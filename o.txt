Equation Chapter 1 Section 1Journal Title
Learning-based On-AP TCP Performance Enhancement
Shirong Lin1, Shouxu Jiang1
1 School of Computer Science, Harbin Institute of Technology, Harbin, 150001, China.

Correspondence should be addressed to Shouxu Jiang; jsx@hit.edu.cn
Abstract
Data transmissions suffer from TCP's poor performance since the introduction of the first commercial wireless services in the 1990s. Recent years have witnessed a surge of academia and industry activities in the field of TCP performance optimization. For a TCP flow whose last hop is a wireless link, congestions in the last hop dominate its performances. We implement an integral data sampling, network monitoring, and rate control software-defined wireless networking (SDWN) system. By analysing our sampled data, we find that there exist strong relationships between congestion packet loss behaviours and the instant cross-layer network metric measurements (states). We utilize these qualitative relationships to predict future congestions in wireless links, and enhance TCP performance by launch necessary rate control locally on the APs before the congestions. We also implement modelling and rate control modules on this platform. Our platform senses the instant wireless dynamic and takes actions promptly to avoid future congestions. We conduct real-world experiments to evaluate its performance. The experiment results show that our methods outperform the TCP BBR and a recently proposed protocol PCC-Vivace on throughput, delay, and jitter performance.
Introduction
Mobile traffic and Wi-Fi traffic will account for more than 70.6% by 2022 [1]. At the same time, the 5G and 802.11 ax standards will be launched to the market soon. Moreover, machine learning and software-defined networking (SDN) has achieved great success in practical applications. Among the 70.% of data, the exponential growth of multimedia traffic, the real-time traffic, and the other virtual reality (VR) and augmented reality data have stringent Quality of Service (QoS) constraints. It is apparent that today's prevalent congestion control algorithms, the TCP family, fall short of the critical performance requirement, especially on the last (wireless) hop [2, 3, 7, 8, 9, 11, 12, 13]. Moreover, current transport layer protocols are no longer suitable for the mmWave communication in 5G and Wi-Fi 6 [2]. As the primary functions of TCP protocols, congestion control algorithms are designed to probe and utilize the network capacity efficiently. However, they perform poorly in wireless networks whose capacity varies rapidly with the channel condition, contentions, interferences, mobilities
Researchers of the traditional end-to-end TCP protocols focus on exploring suitable parameters and algorithms to infer the instant link capacity. TCP BBR [11], PCC [12], PCC Vivace [7] and Remy [13] are such protocols. And some other researches point out that congestion management should be pushed to the network edge [49]; TCP benefits from a shorter control loop, where the server is placed at the cellular network edge and can react faster to link impairments [17]. Some research works focus on the TCP performance and their dominating factors, and how to enhance the TCP performances in wireless networks. Research works WiTT [23] reveals the relationships between wireless network measurements and TCP throughput. Research work [35, 36] reveals the relationships between network latency and wireless network measurements.
However, these research results cannot be used directly in TCP optimizations, even though they do reveal the relationships between TCP performance and some of the metrics. Packet drops cause congestions to degrade the TCP performance (throughput and latency). However, there are two kinds of packet drops: the congestion drops and the congestion drops. The non-congestion packet drops happen in the MAC layer while the congestion ones happen when the queues are overloaded. TCP protocols should differentiate these two kinds of packet drops. Data rates should be limited only when there are congestion packet drops. The non-congestion packet dropping events have no relationships with the TCP data rate. Most of the TCP protocols differentiate these two kinds of packet drops by observing the round-trip time (RTT), but these approaches are not accurate. Therefore, we argue that it is not suitable to schedule the TCP data rate only by observing TCP throughputs or latencies; the congestion events should be more appropriate. Then, the problems for the TCP performance enhancements in wireless networks are:
    What does the network states look like when congestion happens? 
    Which factors influence the congestions the most?
    How to avoid Wi-Fi congestions?
We explore the cross-layer network metric measurements on commercial APs to enhance the TCP performance. The cross-layer network states before congestions happen are sampled to learn the qualitative relationships between congestions and these metrics. Then, we propose a learning-based model to predict future congestions, and a receiving window-based rate control method to avoid these congestions. Moreover, we implement the whole system (includes data sample, learning, control) in our SDWN platform and evaluate its performances.
To summarize, our main contributions are: 
    We propose an SDWN-based enterprise-scale measurement study of WiFi congestion loss. Our results detailed reveal the relationships between congestion packet loss and the cross-layer network metrics. We believe these results have implications for all participants in the mobile Internet ecosystem. 
    We model the rate allocation as a utility maximization problem to obtain optimal proportional fair data rate allocations. These data rates are mapped to the rwnds to control the TCP data rates. 
    We implement the whole system in our real-world SDWN platform, and this work is novel in TCP optimization. Moreover, we conduct practical experiments to evaluate its performance. The results show significantly improved WiFi latencies.
The paper is organized as follows: The motivations are introduced in section Motivation. The congestion prediction is introduced in section Congestion Prediction. In section Window Modelling we model the rate allocation as a utility maximization problem, solve it and obtain an optimal window. In section Evaluation we evaluate the performance of our platform. And we conclude our work in section Conclusion.
Related Works
Our work focuses on the congestion packet drop prediction and SDWN-based TCP rate allocation implementations. So, we introduce the related work from two aspects: The development of TCP protocols and the research on the relationships between TCP performance and network states in wireless networks.
The development of the TCP protocols
We classify current TCP protocols into loss-based, delay-based, capacity-based, hybrid-based, proxy-based, ECN, learning-based, and cross-layer ones.
The loss-based and delay-based protocols: Tahoe, Reno, New Reno, and CUBIC are typical loss-based TCP protocols. Loss-based protocols cannot differentiate the congested packet loss from the non-congested packet loss. Moreover, loss-based protocols are aggressive, especially to the delay-based protocols. TCP Vegas, New Vegas, and Verus are delay-based TCP protocols. Delay-based protocols are more stable and perform better on the retransmission and latency performance than the loss-based ones. Also, they can infer the congestions happen on the wireless links by monitoring the round-trip time (RTT). However, their adoption has been blocked for the aggressiveness of existing protocols.
The hybrid protocols: Compound TCP for Windows systems and BBR are hybrid protocols. Compound TCP contains both the loss-based mechanism and the delay-based mechanism. BBR estimates both the RTT and the link capacity; it is a hybrid delay-based and capacity-based protocol. BBR uses recent RTT and delivery rate to model the bandwidth-delay product (BDP) and varies pacing rate to keep inflight near the BDP (for the full pipe but small queue). BBR exhibits high rate variance and a high packet loss rate upon convergence. Also, it is aggressive towards other TCP algorithms.
The learning-based protocols: TCP Remy [13], PCC [12], PCC-Vivace [7], Copa [8], TCP-RL [4], and QTCP [6] are learning-based protocols. Machine-learning methods will be more and more important for the TCP protocol designers. The PCC-Vivace model utility of all TCP flows that share the same bottleneck link as a function of delays and delivery rates. The authors prove there exists a Nash equilibrium for their optimization, and they design an on-line learning algorithm by computing the gradient of the utility function to get the optimal pacing rate. Remy is an off-line machine learning method that aims to produce TCP protocols by mapping observed congestion signals to sender actions. Remy is a cooperative game method, and it needs intense off-line computation, and the performance of Remy depends on the accuracy of the network and traffic models. PCC and Vivace perform on-line non-cooperative game optimizations. PCC is rate-based, and its performance depends on the accuracy of the clocking.
The protocols for wireless networks: Some of the capacity-based protocols are designed to enhance the TCP performance in wireless and lossy links. TCP Westwood, Sprout are two such protocols. However, researches in [52] show that the throughput and delay performance of TCP Westwood is nearly the same as TCP CUBIC. And Sprout seems to be unable to efficiently estimate the capacity of practical wireless links, even without cross-traffic [53].
The ECN and proxy approaches: ECN is an effective way to feedback the congestion reasons to the TCP sender to improve the performance. However, ECN adaption increases very slowly, investigation in [10] shows that only 3.51% of TCP headers request ECN. Proxy solutions implement protocol optimizations in an intermediate network device. A window regulator [37] is used to prevent buffer overflow at the link through modification of the receive window size. This solution works well in wireless networks with small buffers but is no longer suitable, as the buffer size of current devices is often larger than even the maximum receives window size.
WiFi measurements and mathematic modeling
WiFi measurements: Research work [27, 31, 28, 35, 36, 30, 25] focus on WiFi measurements. The author of PIE [27] captures and records wireless frames and analyzes whether two wireless links are mutually interfering if the packets of two links can be transmitted at the same time. However, this analysis requires that all the APs have the same time clock, and the computation complexity is high. The authors of [31] find that TCP performance degrades significantly in a dense usage scenario, even with 20-30 clients per access point, this discovery is contrary to previous research results [50, 51], and they find that the uplink data transmission causes contradicting results. The author of [23] finds that TCP's performance is related to the WiFi measurement metrics. They define WiTT (WiFi-based TCP throughput) as the wireless experience indicator, then regress WiTT with some of the WiFi measurement metrics. Similarly, the authors of [28, 35, 36] predict page load time, packet latency (RTT for ping command) with some of the WiFi metrics. The authors in [30] used a machine learning method to explore the relationship between AP sensing behaviors and the wireless network states (AP sensing processes are launched by clients to find potential APs, and they are time-consuming and can harm the throughputs). The authors in [25] used a machine learning method to identify the ongoing TCP protocols.
Mathematic modeling: Research work [49, 20, 29, 26, 18, 21, 34] focus on model the throughput performance in Wireless networks. The interference caused by rogue APs are modeled in [20], the authors find that hidden terminals cause about 30% MAC layer loss rate increase on average, and the carrier sense interference due to RAPs causes only 5% access delay to increase at the MAC layer. A two-layer credit-based rate control algorithm for wireless networks is proposed in [49]. A mathematical model of throughput in LTE networks is proposed in [29]. Similarly, the authors in [26] use measurements in the physical layer to model the capacity of the wireless links. The measurements in wireless networks are spatio-temporal data; the authors in [18] define a spatio-temporal distance based on which spatio-temporal neighbors. Then, the spatio-temporal load is defined; at last, the authors use machine learning methods to regress the cell loads. Research works in [30] aim to model the packet delay caused by interference, and the author proposed an algorithm to minimize the interference and decrease the packet latencies. The compound TCP in IoT are modeled as several sub-processes in [34]; these sub-processes are congestion window, throughput, packet loss.

Motivations
TCP data transmissions over wireless links are full of congestion packet loss. We believe the happen of congestion packet losses are not sudden events but predictable ones. We conduct an experiment to show the congestions over wireless links and our ideas. 
The deployment is: one desktop computer which wired connects to an AP, a Linux laptop (runs Cubic) which is moving with a person. A TCP sender application who send current \mus-level system time to the TCP server. The server counting the receiving items to calculate the actual TCP rate. We also monitor the TCP states by utilizing Wireshark which can tell us when and which packets are lost. The actual TCP rate, loss rate, and when the retransmissions happened are shown in Fig. 1. The blue curve is the actual TCP rate, and the black points are the retransmission rates. The red curve is the preferred TCP rate achieved by decreasing data rates before congestions.
 
Figure 1: TCP data transmissions over wireless links. The blue line is the actual data rate, and the black dot is the retransmission ratio (congestion packet dropping ratio), and it corresponds to the right y-axis. The red line is the expected data rate, i.e., a data rate achieved by an algorithm that can predict and avoid the congestion packet drops.
The processes we enhance the TCP performance is described in Fig. 2. Downlink packet P_1,P_2,\ldots are transmitted from the remote server to mobile device. The RTT for wired links is 2T seconds. We predict congestion will happen in the future 2T seconds, and we learn from computing that the congestion window (cwnd) should be limited to 7000. Then we modify the receiving window (rwnd) in the ACK packets from 10000 to 7000 to avoid future congestions. The non-congestion scenarios are not considered in this article.
Two problems are essential for the TCP enhancing processes aforementioned. When and how to act, i.e., the congestion prediction based on cross-layer network statistics, and the optimal window set in ACK packets. We describe our works on congestion prediction and window modeling in section Congestion Prediction and section Window Modelling respectively.
 
Figure 2: On-AP TCP performance enhancement
Congestion Prediction
To build a single unified model for the congestion packet loss ratio is challenging. The challenges come from four aspects. Firstly, more than nine factors can affect packet congestions, and the relations between congestion packet loss and each of them are not linear, nor monotonic as explained before. Secondly, some of the related factors are mutually correlated. For example, channel utilization, receiving utilization, and transmitting utilization are mutual related. Thirdly, it is challenging to model the wireless channels that dominate wireless communication processes even several channel models are proposed. Fourthly, it is also challenging to model the queuing algorithm, MAC protocols, and the wireless drivers that affect packet congestions. So, we choose the learning-based method in this article, i.e., sample all suspect metrics and learn their relationships with congestion packet loss, mark them, and build and evaluate a corresponding supervised learning model.
Sampling and Data Collection
Congestions collection: Congestion packet loss cannot be obtained directly from the sampled packet information. There are two kinds of packet loss on the AP, the congestion packet loss in queue processes, and the non-congestion ones in the driver (can be obtained in Mac80211). The total amount of packet loss minus the amount of non-congestion ones is the number of congestion ones. To get the total amount of packet loss, we confirm retransmission by checking the sequence of each packet and its payload. And the losses in MAC80211 can be obtained when the packet dropping event happens.
Related factors collection: The related factors are the cross-layer metric measurements before the congestion happens. They contain metric measurements of the transport-layer, network layer, MAC layer. Most of them are sampled at 250 Hz; packet information is sampled for each data packet. Beacon information is sampled at 10 Hz, and the details are listed in Table 1. Most of the cross-layer network metrics we sampled are listed in Table 2, the others that have weak IG index and Kendall index are omitted. IG is a general index to quantify the predictable relationships, and the Kendall index is a general index to quantify the monotonic relationships. The larger the absolute value of the IG index, the stronger the predictable relationship. Moreover, a significant absolute value of the Kendall index also means there exists a remarkable correlation between two vectors.
Table 1: Categories, sources and sample rates of sampled information
Module  Location    Layer   Rate
Packet  Open vSwitch, kernel    Transport & Network Each pkt
Link    Mac80211, kernel    Mac Layer   250 Hz
Channel Mac80211, kernel    Mac Layer   250 Hz
Queue   Sch_generic.c, kernel   Kernel  250 Hz
Beacon  Mac80211, kernel    Mac Layer   10 Hz
Drops   Mac80211, codel.h   Mac layer   Each drop
Two instructions should be explained beforehand.
    For our APs (NetGear WNDR 3800/4300), the OpenWrt maintains five queues: 1, 2, 3, 4, and 5. Nearly all the data are transmitted in queue 3, but when data bursts occur, some of them are transmitted in queue 5.
    There are four kinds of channel utilization in this paper: Channel utilization, receiver utilization, transmitter utilization, and scan utilization. They correspond to time_busy, time_rx, time_tx, and time_scan metrics that obtained from Mac80211.
The sample modules sample the real-time data, remove the redundancies, and then transmit them to the data receiver runs on the controller. The receiver pre-processes the real-time data into training data items for learning algorithms.
 
Figure 3: Wi-Fi congestion retransmission distribution.
Large-scale measurement study: We ran the sampling modules on NETGEAR 4300 access points and deployed 12 such APs in the library of the Harbin institute of technology. We also provided VPN services and Internet access services to encourage potential users to access our free APs. Additionally, we replaced the origin APs of our laboratory center with four of our APs to provide Internet access services. We collected about 1060.9GB (600.9 GB TCP headers, and 460GB cross-layer statistics) raw data. Our dataset contains hundreds of millions of records from more than 3300 mobile devices. Based on our surveys, this dataset is unprecedented, and no such datasets were collected before. And we will deploy more APs and cover the whole campus in the future to obtain more representative data.
We can get several high-level findings from the dataset. (1) Public wireless networks are crowded, and ill configured. Our AP in room 419, Zonghe building (a 10-layer and about 16 rooms every layer) can detect more than 200 running APs. The data sampled from the library shows that more than 1200 APs (includes Wi-Fi Hotpoints) appear in the 30-days' data. Statistics of our data show that nearly 48.2% of APs utilize channel 6, 25.7% of the APs utilize channel 11, 16.1% of the APs utilize channel 1, and only 10% of the APs utilize the other channels; (2) TCP congestion retransmission frequently happens in wireless networks, Fig. 3 shows that the congestion retransmission ratio is 6.7677%; (3) RTT is stable in the wired links. (4) The number of congestion packet drops is much more than the number of non-congestion packet drops. 5)retransmission ratio has a long tail distribution. 
Table 2: The collected metrics and their Kendall \& IG index with congestion packet loss ratios
Radio factor     Kendall     Information gain
backlog of queue 3  0.3307  0.1405
channel utilization 0.5413  0.1694
All dropped in queues   0.3109  0.1838
All dropped in queue 3  0.3057  0.182
Receive bytes in queue 3    0.4082  0.1504
Receive bytes in queue 3    0.4082  0.1504
Received packets in queue 5 0.0138  0.1403
Requeues in queue 3 0.3128  0.0869
All the transmission retries over the links -0.02   0.0157
All the transmission bytes over the links   0.2898  0.0091
All the received bytes over the links   0.2557  0.0058
All the transmission failed over the links  -0.007  0.0032
Noise   -0.1386 0.003
Data rate counted in Open vSwitch datapath  0.8 0

%\par The Fig. 3 shows the CDF distribution of the retransmission ratio obtained from our dataset. The median of the ratio is 3.5%, the {90}^{th} percentile is around 33%, and the {99}^{th} percentile is 77%. The ratio for 3.57%, 33%, 77% is {50}^{th}, {90}^{th}, and {99}^{th}, we can conclude that this retransmission ratio has typical long-tail distribution characters. Long-tail distribution of retransmission ratio means some users or applications are suffering from severe congestions.
Measurement study and congestion loss classification: Although lots of works are focused on the preprocessing, we omit them here. To get real-time prediction models, we implement modules to pre-process the sampling data while receiving. The observation results, qualitative relationships study, and the classification processes are introduced in this subsection.
Observations: From the collected dataset, we find that several cross-layer network metrics, especially the queue-related factors, have strong qualitative relationships with the congestion loss rate. We choose nine of them and draw the relationships in Fig.4. Of these figures, the black lines are the distributions of the related cross-layer network metrics, and the red dotted lines are the congestion loss rates distributed over the metrics. We explain two subfigures here as examples. Subfig (a): When the network states are poor, then the arriving rate will be low and lots of congestions. Subfig (d): the backlog of queue 3 has more straight relationships with the congestion packet loss rate, the larger the queue backlog, the higher the loss ratio.
Qualitative Relationships: The IG indexes and Kendall indexes between congestion packet loss ratio and the related factors are listed in Table 2. We can learn from this table that backlog of queue 3, channel utilization, drops in queues, and arriving rates have strong qualitative relationships with congestion loss ratio.
Classification: To assist in interpreting the losses in terms of their impact on well-known applications, the authors of [39] categorize the losses into six classes. In this article, we re-classify these six classes into four classes. Table 3 lists the details. We label the training data with these four labels.
Table 3: Classes of WiFi congestion loss ratios [39]
WiFi retrans class   Loss Range  Our Classes
Excellent    < 0.1%  Good
Good     0.1% and < 1%   Good
Acceptable   1% and < 2.5%   Acceptable
Poor     2.5% and < 5%   Acceptable
Very Poor    5% and < 12%    Poor
Bad        12%   Bad
Supervised learning algorithms are useful methods to model the congestion packet loss ratio. In this section, we explore the congestion prediction performance of supervised learning algorithms.
Table 4: Performances of the 4-class classifiers
Items    Decision tree   Random forest
Precision    [0.680 0.431 0.485 0.612]   [0.680 0.504 0.627 0.795]
Recall   [0.677 0.432 0.485 0.626]   [0.829 0.446 0.489 0.594]
F-score      [0.679 0.432 0.485 0.622]   [0.747 0.423 0.549 0.680]
We choose several typical supervised learning methods to model the congestion loss ratio. They are decision tree (DT), random forest (RF), support vector machine (SVM), k-nearest neighbour (KNN), and neural network (NN). Their performance is evaluated by the precision-recall curve (PR-curve) [40]. The curves are shown in Fig. 5, from which we can learn that decision tree and random forest methods outperform the others. Moreover, the precision and recall performance on our training set is listed in Table Ⅳ, and the performance is acceptable [35].
The decision tree is easier to be implemented on the APs, so we choose it.
\par We draw a 5-depth decision tree example as in Fig. 6. Not all the metrics are shown in this figure because we set the max_depth as 5. The scale of the practical decision trees that run on AP has a higher depth. The decision tree puts important metrics near the root; metrics close to the root have more effect on AP load. 
The controller generates a decision tree every 1 second by using the latest 10000 training items. The new trees are then transmitted to the corresponding APs to replace the older trees.
Utility-based Window Modelling
The decision tree is transmitted from the controller to the corresponding AP. We implement a parsing function to decode received information and create the decision tree on the AP. After lots of complicated operations between the user space and Kernel, the cross-layer network states are obtained and inputted into the decision tree in real-time to predict the congestions. The outputs decide whether we should launch rate controls. When the outputs are "Poor" or 
"Bad," new advertisement windows should be calculated and replace the ones in ACKs. We model the rate allocation problem as a utility maximization problem in this section.
 
Figure 4: Distribution of factors, and their relationships with WiFi congestions.
Suppose the set of flows for AP_k is \mathcal{L}_\mathcal{k}=\{1,2,\cdots,L\}, and for flow i\in\mathcal{L}_\mathcal{k}, the data rate is x_i. For i\in\mathcal{L}_\mathcal{k}, the congestion packet dropping model is as the following:
      
        (1.1)
where C\left(t\right) is the capacity of links associated with the APs, it is time-varying in wireless networks, and we obtain it from historical data. C\left(t\right) is set to the data rate of its nearest non-congested time slot.
 
Figure 5: The precision-recall curve for different classification algorithms.

We model a utility for each data flow, this utility is based on its data rate x_i and congestion packet dropping probability l_i. The utility for data flow i is as the following:
        (1.2)
where c_i is the weight of flow i, and \sum\sqrt{c_i}=\sqrt{C\left(t\right)}. The network utility for AP_k is U_k=\sum_{i\in\mathcal{L}_\mathcal{k}}u\left(x_i,l_i\right). And the TCP optimization problem turns into an optimization maximization problem.

Taking the first derivative of the utility function, we obtain the followings:
        (1.3)
and utilize the condition \sum_{j\in\mathcal{L}_\mathcal{k}}x_j=C\left(t\right), we can obtain the following:
        (1.4)
The obtained data rate should be mapped to the rwnd. Two things should be known in this process: current cwnd, and historical mapping relationships between cwnds and data rates. It is challenging to obtain cwnd on intermediate network devices. However, a machine learning method is proposed in [14] to infer the windows. The rate-window mapping relationships can be obtained from historical data. 
 
Figure 6: A 5-depth decision tree for modelling the effects of related factors on retransmissions. Some of the metrics are not shown because of the depth.
Evaluation
We conduct evaluations to characterize the throughput, delay, jitter, fairness, and retransmission performance of our method. Our method is an on-AP learning method, so we name it as OAL (on-AP learning). OAL is not a protocol, and it is a module that runs on Cubic protocol, it helps to enhance the performance of Cubic. We compare the OAL method with the BBR protocol and Pcc-Vivace [7] method. The evaluating objects are throughput, delay, jitter, retransmission ratios, and the Jain’s index.
Experimental Setup
We carry out the evaluations on our real-world testbed. We have introduced in [5] how we built this SDWN testbed, so we omit the introductions here. Fig. 7 describes the deployment of evaluations. The experiment scale is the same as the one in [15]. As described in the sections mentioned above, our system contains a server (runs the controller), three APs, and nine wireless stations. The server is an HP Z420 work station that runs the Debian system. The Ryu controller runs on the server. The APs are Netgear 4300 routers that run OpenWRT 15.05.01(empower-lede) and Open vSwitch 2.8.2. Nine Laptops act as the wireless stations, and they run the Debian system. All the evaluations were running on the 2.4 GHz ISM band. The connection relationships are shown in Fig. 7.
 
Figure 7: Deployment of APs and clients in the experiments.
The evaluation processes: During the experiment, the controller also acts as iperf3 servers, we open nine TCP flows on it, and each flow corresponds to a client. For each of the evaluated methods, we run experiments for ten iterations, and each iteration lasts 600 seconds. The outputs of iperf3 are stored in both server sides and client sides to calculate throughput performance. We also implement a C program (running on clients) that probes and parses TCP information from the kernel in the server (actually, this program acts as a simple version of the "ss" command in Linux). From the obtained, we can obtain the delay and jitter performances of the clients.
 
Figure 8: Network-wide throughput performance for the algorithms.
Experimental Results
In this paper, we utilize the Jain fair index to quantify the fairness of throughput, delay and jitter performances. The Jain fair index is denoted by the following equation:
        (1.5)
where J_k represents the metric of AP k, A is the set of APs, and m is the amount of APs.
 
Figure 9: Network-wide delay performance for the algorithms.
The overall throughput, and Jain's index of the three AP's data rates are listed in Fig. 8. The average throughput of OAL is 17.5% more than BBR and 16.5% than Vivace; the throughput fairness performance is lightly weaker than BBR. 
 
Figure 10: Network-wide jitter performance for the algorithms.
The overall delay and fairness performance are shown in Fig. 9. The average delay of OAL is 0.70 of BBR and 0.74 of Vivace, and the delay performance is fairer than the others. 
The overall delay and fairness performance are shown in Fig. 10. The average jitter of OAL is 0.98 of Vivace and 0.84 of BBR.
The overall retrains performance are shown in Fig. 11. The retransmission ratio of OAL is 12.6% less than Vivace, and 25.2% than BBR.
 
Figure 11: Network-wide congestion packet loss ratio for the algorithms.
Discussion
BBR exhibits high rate variance and high packet loss rate upon convergence, however, the convergences of wireless links are lengthy processes. Vivace try to achieve the Nash equilibrium among data flows; it is a learning-based method that estimates the capacity of the link by monitoring delay and rate. However, the relationships between congestion and these two factors are complex [2]. Our method monitors the network states and predicts the congestions by the chosen learning model. Our method can get current network states instantly and acts immediately. Naturally, our algorithm can perform better.
Conclusion
We implement an SDWN platform, and several sampling modules to sample instant network metric measurements. The obtained training data can comprehensively reveal the qualitative relationships between congestion packet drops and these cross-layer network metrics. Especially the queue-related metrics that are not used in previous researches, and they have strong relationships with congestions. Our platform has several advantages. Firstly, it is prompt. It is implemented on the APs and can get the instant network states. Moreover, the prediction model (decision tree in our project) is also implemented on the APs, so the network states can instantly trigger its actions. Secondly, it is comprehensive. The data samples (training set) come from the transport layer, the network layer, and the MAC layer. Thirdly, it is scalable. We implement our methods in SDWN, which has excellent compatibility. These three advantages guarantee a better performance for our platform.
Data Availability
Data available on request, we have about 1 TB raw data. We have described the content of data in this article.
Conflicts of Interest
There are no conflicts of interest.
Funding Statement
This work was supported in part by the National Natural Science Foundation of China under Grant 61370214 and Grant 61300210.
Acknowledgments
None.
Supplementary Materials
None.
